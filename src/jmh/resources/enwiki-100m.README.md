Text extracted from Wikipedia
=============================

The file `enwiki-100m.txt.gz` contains approximately 100 million tokens
(about 3.5% of the entire Wikipedia)
extracted from the **English Wikipedia 20180301 dump**,
in no particular article order. Not all articles are included.
Processing errors may cause garbage to be included, and text to be missing.
This file is raw text meant for benchmarking word counting,
and thus we cannot include detailed metadata, such as author information.
Please see the original Wikipedia articles as of 2018-03-01
for full authorship attribution.

Above file is best seen as a joint work by all Wikipedia authors;
including, but not limited to:
Ser Amantio di Nicolao,
Koavf,
Rich Farmbrough,
Waacstats,
BD2412,
Materialscientist,
Bearcat,
Hmains,
Magioladitis,
Rjwilmsi,
Tom.Reding,
Tim!,
BrownHairedGirl,
Tassedethe,
Lugnuts,
Good Olfactory,
Woohookitty,
Dr. Blofeld,
Frietjes,
Northamerica1000,
and thousands of other authors.

The file is licensed CC-BY-SA, using the
[**Creative Commons Attribution-ShareAlike 3.0 Unported License**](http://creativecommons.org/licenses/by-sa/3.0/),
same license as Wikipedia.

For more details on the Wikipedia license, see:
https://en.wikipedia.org/wiki/Wikipedia:Reusing_Wikipedia_content

Because the file is too large, it is stored in `git-lfs`, the git large file storage.
